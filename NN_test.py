# -*- coding: utf-8 -*-
"""test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z3SyMc_EJ-_eKchrwBZ4_AJiciuOGuYN
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras import utils
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Dense
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Normalizer
from sklearn.preprocessing import Binarizer
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

file_directory = input('Введите название файла: ') #вводится название файла для работы с ним

data = pd.read_excel(file_directory, sheet_name='Final Data') #читается файл расширения эксель

data #Ожидаем, что в файле будет первый столбец - это профессии, последующие - результаты тестов

data.head()

inputs = data.iloc[:,1:] #отделяем первый столбец от результатов тестов

goal = data.iloc[:,0] # первый столбец, будет использоваться как цель

inputs.dropna(axis=1, how='all', inplace=True)

inputs.head()

mean_inputs = inputs.mean(axis='columns')
mean_inputs.plot()

df = pd.DataFrame(mean_inputs)

scaler = StandardScaler().fit(df)
scaler_inputs = scaler.transform(df) #все ответы в тестах стандартизируем

scaler_inputs

plt.plot(scaler_inputs)
plt.show()

from sklearn.preprocessing import LabelBinarizer

lb = LabelBinarizer()
goal_enc = lb.fit_transform(goal)

goal_enc

train = float(input('Введите процент выборки (если 80%, то вводим 0.8): '))

X_train,X_test,y_train,y_test = train_test_split(scaler_inputs, goal_enc, train_size=train)

X_train.shape

#Создание и сборка архитектуры

model = Sequential()
model.add(Input(X_train.shape[1]))
model.add(Dense(X_train.shape[1], activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(500, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(500, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(y_test.shape[1], activation='softmax'))

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

best_callbacks = model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath='best callback',
    save_weights_only=True,
    monitor='accuracy',
    mode='max',
    save_best_only=True)

epoch = int(input('Введите количество эпох:'))

training = model.fit(x= X_train, y= y_train, validation_data=(X_test,y_test), epochs=epoch, shuffle=True, batch_size=32, callbacks=[best_callbacks])

plt.figure(figsize=(10,6))
plt.plot(training.history['loss'], label='losses')
plt.plot(training.history['val_loss'], label='validation losses')
plt.title('Validation losses and Usual losses')
plt.show()

plt.figure(figsize=(10,6))
plt.plot(training.history['accuracy'], label='accuracy')
plt.plot(training.history['val_accuracy'], label='validation accuracy')
plt.title('Validation accuracy and Usual accuracy')
plt.show()

"""## Оценка предсказаний

"""

from sklearn.model_selection import cross_val_score 
from sklearn.linear_model import LogisticRegression 
from sklearn.datasets import make_classification

features = X_train
target = y_train

features, target = make_classification(n_samples = 10000,n_features = 3,n_informative = 3, 
n_redundant = 0, 
n_classes = 3, 
random_state = 1)

logit = LogisticRegression()

cross_val_score(logit, features, target, scoring='accuracy')

"""# Визуализация результативности"""

from sklearn.metrics import confusion_matrix

from sklearn.preprocessing import LabelEncoder

Y_train = LabelEncoder().fit_transform(goal)

X_train.shape

Y = Y_train[0:45]

Y.shape

features_train = X_train
target_train = Y
features_test = X_test

target_predicted = logit.fit(features_train, target_train).predict(features_test)

target_test = Y_train[45:]

matrix = confusion_matrix(target_test, target_predicted)

dataframe = pd.DataFrame(matrix)

dataframe

import seaborn as sns

sns.heatmap(dataframe, annot=True, cbar=None, cmap="Blues")
plt.title("Матрица ошибок")
plt.tight_layout()
plt.ylabel("Истинный класс")
plt.xlabel("Предсказанный класс")
plt.show()

"""## Evolution

"""

#Формирование и сохранение нейросети 
evalution = model.evaluate(X_test,y_test)

model.save('classifier.h5')

prediction = model.predict(X_test[4,:])

X_test.shape

prediction

# Предсказания модели
from sklearn.metrics import classification_report

target_names = ['developer', 'designer', 'product manager', 'others']

y_pred = prediction

print(classification_report(np.argmax(y_test,axis=1), np.argmax(y_pred,axis=1), target_names=target_names))

results = pd.DataFrame(prediction)

probability = results.set_axis(['Developer','Designer','Product manager','Other'], axis=1)

print(probability)

